{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# Startzeitpunkt erfassen\n",
    "start_time = time.time()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yahooquery as yq\n",
    "import datetime as dt\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import os\n",
    "import yfinance as yf\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import openpyxl\n",
    "from openpyxl.styles import PatternFill\n",
    "from openpyxl.utils import get_column_letter\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inputdaten einlesen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dialogfenster erzeugen\n",
    "root = tk.Tk()\n",
    "root.withdraw()\n",
    "root.attributes(\"-topmost\", True)\n",
    "root.lift()\n",
    "\n",
    "# Dateiname Inputtabelle\n",
    "input_data = filedialog.askopenfilename(title = \"Watchliste öffnen\", initialfile=\"Watchliste\", filetypes=((\"Excel-Dateien\", \".xlsx\"), (\"alle Dateitypen\", \".*\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Einlesen der Excel-Datei\n",
    "input_namen = {\"Asset\": str,\n",
    "               \"Symbol (Yahoo)\": str,\n",
    "               \"ISIN\": str,\n",
    "               \"Benchmarkindex\": str,\n",
    "               \"Symbol Benchmark\": str,\n",
    "}\n",
    "df_input_data = pd.read_excel(input_data, names= input_namen.keys(), dtype= input_namen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks =[]\n",
    "benchmarks = []\n",
    "df_symbols_mapping = ()\n",
    "\n",
    "list_assets = df_input_data[\"Symbol (Yahoo)\"].tolist()\n",
    "list_benchmarks = df_input_data[\"Symbol Benchmark\"].tolist()\n",
    "\n",
    "for asset in list_assets:\n",
    "    stocks.append(yq.Ticker(asset))\n",
    "\n",
    "for benchmark in list_benchmarks:\n",
    "    benchmarks.append(yq.Ticker(benchmark))\n",
    "\n",
    "df_symbols_mapping = pd.DataFrame({\"symbol\": list_assets, \"benchmark\": list_benchmarks})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = dt.date.today()\n",
    "\n",
    "def get_previous_business_day(date):\n",
    "    # datum um \"date\" Monate zurückrechnen, wobei z.B. 3 Monate vom 31.05. zurück -> 28.02. ergibt\n",
    "    previous_date = today + relativedelta(months=-date)\n",
    "    # Überprüfen, ob der gegebene Tag ein Werktag ist\n",
    "    # (Montag = 0, Sonntag = 6)\n",
    "    if previous_date.weekday() > 4:\n",
    "        delta = previous_date.weekday() - 4\n",
    "        previous_date -= dt.timedelta(days=delta)\n",
    "    return previous_date\n",
    "\n",
    "# Liste mit Heutigem Datum\n",
    "actual_date = [today, \"heute\"]\n",
    "\n",
    "# Das Datum von vor 1 Monat ermitteln\n",
    "previous_1_month = [get_previous_business_day(1), \"vor 1 Monat\"]\n",
    "\n",
    "# Das Datum von vor 2 Monaten ermitteln\n",
    "previous_2_months = [get_previous_business_day(2), \"vor 2 Monaten\"]\n",
    "\n",
    "# Das Datum von vor 3 Monaten ermitteln\n",
    "previous_3_months = [get_previous_business_day(3), \"vor 3 Monaten\"]\n",
    "\n",
    "# Das Datum von vor 6 Monaten ermitteln\n",
    "previous_6_months = [get_previous_business_day(6), \"vor 6 Monaten\"]\n",
    "\n",
    "# Das Datum von vor 1 Jahr ermitteln\n",
    "previous_1_year = [get_previous_business_day(12), \"vor 1 Jahr\"]\n",
    "\n",
    "df_previous_days =  pd.DataFrame([actual_date, previous_1_month, previous_2_months, previous_3_months, previous_6_months, previous_1_year], columns=[\"Dates\", \"Description\"])\n",
    "df_previous_days[\"Dates\"] = pd.to_datetime(df_previous_days[\"Dates\"]).dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ermitteln ob ein Tag ein Börsentag ist\n",
    "def is_business_day(date):\n",
    "    # Überprüfen, ob der gegebene Tag ein Werktag ist (Montag = 0, Sonntag = 6)\n",
    "    if date.weekday() >= 5:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# Ermitteln des nächsten Börsentages, falls für den Earnings Announcement- oder Post-Announcementtag kein Kurs gefunden wird\n",
    "def get_next_trading_day(date):\n",
    "    if date in df_prices[\"date\"].values:\n",
    "        return date\n",
    "    else:\n",
    "        next_trading_day = df_prices[df_prices[\"date\"] > date][\"date\"].min()\n",
    "        return next_trading_day"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abfrage der Daten von Yahoo Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Termine der vergangenen Bekanntgaben von QUartalszahlen ermitteln\n",
    "# df_earnings_latest = nur die aktuellsten QUartalszahlen je Ticker\n",
    "# df_earnigns = die vergangenen Quartalszahlen je Ticker (hier nicht benötigt)\n",
    "\n",
    "df_earnings_data = pd.DataFrame()\n",
    "df_earnings = pd.DataFrame()\n",
    "\n",
    "for asset in list_assets:\n",
    "    df_earnings_data = yf.Ticker(asset).get_earnings_dates()\n",
    "    df_earnings_data[\"symbol\"] = asset\n",
    "    df_earnings_data[\"Description\"] = \"earnings announcement\"\n",
    "    df_earnings = pd.concat([df_earnings, df_earnings_data])\n",
    "    time.sleep(1.3)\n",
    "\n",
    "df_earnings = df_earnings.reset_index()\n",
    "# Umwandlung des Datums in die Form \"2024-01-22\"\n",
    "df_earnings[\"Dates\"] = pd.to_datetime(df_earnings[\"Earnings Date\"], utc= True).dt.strftime('%Y-%m-%d')\n",
    "df_earnings.drop([\"Earnings Date\"], axis= 1)\n",
    "\n",
    "df_earnings_latest = df_earnings[df_earnings[\"Dates\"] < str(today)].sort_values(\"Dates\", ascending=False)\n",
    "df_earnings_latest = df_earnings_latest.groupby(\"symbol\").first().reset_index()\n",
    "df_earnings_latest = df_earnings_latest.set_index(\"Dates\", drop=True)\n",
    "\n",
    "# Series umwandeln in ein Data Frame inkl. einer Spalte mit Beschreibung\n",
    "df_earnings_latest.loc[\"Dates\"] = pd.to_datetime(df_earnings[\"Dates\"], format=\"%Y-%m-%d\")\n",
    "df_earnings = df_earnings.dropna(subset=[\"Reported EPS\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Frame mit den Datumsangaben inkl. Beschreibung der Daten zusammenfügen\n",
    "df_dates = pd.concat([df_previous_days, df_earnings])\n",
    "df_dates = df_dates.reset_index(drop=True)\n",
    "df_dates = df_dates[[\"symbol\", \"Dates\", \"Description\"]]\n",
    "df_dates = df_dates.dropna(subset=[\"Dates\"])\n",
    "df_dates = df_dates.sort_values(by=(\"Dates\"), ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kursabfrage des letzten Jahres\n",
    "df_kurse = pd.DataFrame()\n",
    "df_benchmarks = pd.DataFrame()\n",
    "df_prices = pd.DataFrame()\n",
    "\n",
    "for stock in stocks:\n",
    "    stock_data = stock.history(period=\"1y\", interval=\"1d\")\n",
    "    df_kurse = pd.concat([df_kurse, stock_data])\n",
    "    time.sleep(1.3)\n",
    "\n",
    "for benchmark in benchmarks:\n",
    "    benchmark_data = benchmark.history(period=\"1y\", interval=\"1d\")\n",
    "    df_benchmarks = pd.concat([df_benchmarks, benchmark_data])\n",
    "    time.sleep(1.3)\n",
    "\n",
    "df_kurse = df_kurse.reset_index()\n",
    "df_benchmarks = df_benchmarks.reset_index()\n",
    "df_kurse[\"date\"] = pd.to_datetime(df_kurse[\"date\"], utc=True).dt.strftime(\"%Y-%m-%d\")\n",
    "df_benchmarks[\"date\"] = pd.to_datetime(df_benchmarks[\"date\"], utc=True).dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Unnötige Spalten entfernen\n",
    "df_kurse_new = df_kurse[[\"symbol\", \"date\", \"close\"]]\n",
    "df_benchmarks_new = df_benchmarks[[\"symbol\", \"date\", \"close\"]]\n",
    "df_kurse_new = df_kurse_new.rename(columns={\"close\": \"previous close\"})\n",
    "df_benchmarks_new = df_benchmarks_new.rename(columns={\"symbol\": \"benchmark\", \"close\": \"previous close\"})\n",
    "\n",
    "# Data Frames zusammenführen (zuerst via Mappingtabelle)\n",
    "df_prices = pd.merge(df_kurse_new, df_symbols_mapping, how=\"left\", on=\"symbol\")\n",
    "df_prices = pd.merge(df_prices, df_benchmarks_new, how=\"left\", on=(\"date\", \"benchmark\"), suffixes=(\"\", \"_benchmark\"))\n",
    "df_prices[\"date\"] = pd.to_datetime(df_prices[\"date\"]).dt.strftime(\"%Y-%m-%d\")\n",
    "df_prices = df_prices.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fundamentalkennzahlen der letzten 3 Geschäftsjahre abfragen\n",
    "df_fundamentals = pd.DataFrame()\n",
    "\n",
    "for stock in stocks:\n",
    "    df_fundamentals = pd.concat([df_fundamentals, (stock.get_financial_data(types=[\"BasicEPS\", \n",
    "                                                                             \"DilutedEPS\", \n",
    "                                                                             \"EBIT\", \n",
    "                                                                             \"TotalRevenue\", \n",
    "                                                                             \"MarketCap\", \n",
    "                                                                             \"EnterpriseValue\", \n",
    "                                                                             \"CommonStockEquity\", \n",
    "                                                                             \"NetIncome\", \n",
    "                                                                             \"TotalAssets\", \n",
    "                                                                             \"priceToBook\", \n",
    "                                                                             \"lastFiscalYearEnd\"]))\n",
    "                                                                             ])\n",
    "    time.sleep(1.3)\n",
    "\n",
    "df_fundamentals = df_fundamentals.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analystenmeinungen\n",
    "dict_analysts = {}\n",
    "for stock in stocks:\n",
    "    tmp_dict_var = pd.DataFrame(stock.financial_data)\n",
    "    dict_analysts = {**dict_analysts, **tmp_dict_var}\n",
    "    time.sleep(1.3)\n",
    "\n",
    "df_analysts = pd.DataFrame(dict_analysts)\n",
    "df_analysts.set_index(keys=df_analysts.columns[0])\n",
    "df_analysts = df_analysts.loc[[\"recommendationMean\", \"numberOfAnalystOpinions\", \"returnOnEquity\"],:]\n",
    "df_analysts = df_analysts.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aktuelle Fundamentalkennzahlen\n",
    "dict_fundamentals_current = {}\n",
    "tmp_dict_var = {}\n",
    "for stock in stocks:\n",
    "    tmp_dict_var = pd.DataFrame(stock.summary_detail)\n",
    "    dict_fundamentals_current = {**dict_fundamentals_current, **tmp_dict_var}\n",
    "    time.sleep(1.3)\n",
    "\n",
    "df_fundamentals_current = pd.DataFrame(dict_fundamentals_current)\n",
    "df_fundamentals_current.set_index(keys=df_fundamentals_current.columns[0])\n",
    "df_fundamentals_current = df_fundamentals_current.loc[[\"trailingPE\", \"forwardPE\",\"marketCap\"],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Künftige Quartalszahlen (Schätzungen)\n",
    "# Alle Zahlen abfragen (nested/verschachteltes Dictionary)\n",
    "dict_earnings_future = {}\n",
    "tmp_dict_var = {}\n",
    "for stock in stocks:\n",
    "    tmp_dict_var = pd.DataFrame(stock.earnings_trend)\n",
    "    dict_earnings_future = {**dict_earnings_future, **tmp_dict_var}\n",
    "    time.sleep(1.3)\n",
    "\n",
    "# Erzeugen eines neuen Dictionarys, das gefiltert nach \"trend\" (so ist die Bezeichnung des Keys) sowie nach den Perioden \"0y\" (aktuelles Jahr) und \"+1y\" (nächstes Jahr), sowie nur die benötigten Keys \"epsTrend\" und \"epsRevisions\" enthält\n",
    "dict_filtered_data = []\n",
    "for key, value in dict_earnings_future.items():\n",
    "    for trend in value[\"trend\"]:\n",
    "        if trend[\"period\"] in [\"0y\", \"+1y\"]:\n",
    "            dict_filtered_data.append({\n",
    "                \"symbol\": key,\n",
    "                \"period\": trend[\"period\"],\n",
    "                \"epsTrend\": trend[\"epsTrend\"],\n",
    "                \"epsRevisions\": trend[\"epsRevisions\"]\n",
    "            })\n",
    "\n",
    "# Erzeugen des DataFrames\n",
    "df_earnings_future = pd.DataFrame(dict_filtered_data)\n",
    "df_earnings_future = pd.concat([df_earnings_future.drop([\"epsTrend\"], axis=1), df_earnings_future[\"epsTrend\"].apply(pd.Series).add_prefix(\"epsTrend_\")], axis=1)\n",
    "df_earnings_future = pd.concat([df_earnings_future.drop([\"epsRevisions\"], axis=1), df_earnings_future[\"epsRevisions\"].apply(pd.Series).add_prefix(\"epsRevisions_\")], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anlegen des Ergebnis-Dataframes mit den einzelnen Assets als Zeilenindex\n",
    "df_results = []\n",
    "df_results = pd.DataFrame(index= list_assets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Punkte für RoE\n",
    "# Wenn >20% dann +1, wenn <10% dann -1, sonst 0\n",
    "\n",
    "# Funktion zur Bewertung:\n",
    "def calculate_roe(calc):\n",
    "    if isinstance(calc, dict):  # Überprüfen, ob der Wert ein Dictionary ist\n",
    "        if \"value\" in calc:\n",
    "            calc = calc[\"value\"]\n",
    "        else:\n",
    "            return \"keine Daten\"  # Wenn \"value\" nicht im Dictionary vorhanden ist, gib 0 zurück\n",
    "    if calc is None:\n",
    "        return \"keine Daten\"\n",
    "    elif calc > 0.2:\n",
    "        return 1\n",
    "    elif calc >= 0.1 and calc <= 0.2:\n",
    "        return 0\n",
    "    elif calc < 0.1:\n",
    "        return -1\n",
    "\n",
    "df_results[\"RoE\"] = df_analysts[\"returnOnEquity\"].apply(calculate_roe)\n",
    "df_analysts[\"Score RoE\"] = df_analysts[\"returnOnEquity\"].apply(calculate_roe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Punkte für EBIT-Marge\n",
    "# Wenn >12% dann +1, wenn <6% dann -1, sonst 0\n",
    "\n",
    "# Funktion zur Bewertung:\n",
    "def calculate_ebit_margin(row):\n",
    "    ebit = row[\"EBIT\"]\n",
    "    revenue = row[\"TotalRevenue\"]\n",
    "    if (ebit is None) | (revenue is None):\n",
    "        return \"keine Daten\"\n",
    "    elif (ebit/revenue) > 0.12:\n",
    "        return 1\n",
    "    elif (ebit/revenue) >= 0.06 and (ebit/revenue) <= 0.12:\n",
    "        return 0\n",
    "    elif (ebit/revenue) < 0.06:\n",
    "       return -1\n",
    "\n",
    "# Sortiere das Dataframe Fundamentals nach Datum, um im nächsten Schritt jeweils den aktuellsten vollständigen Eintrag zu wählen\n",
    "df_ebit_sorted = []\n",
    "df_ebit_sorted = df_fundamentals.sort_values(\"asOfDate\", ascending=False)\n",
    "\n",
    "# Gruppiere das Dataframe nach dem Symbol und wähle die erste Zeile für jedes Symbol aus\n",
    "df_ebit_latest = df_ebit_sorted.groupby(\"symbol\").first().reset_index()\n",
    "df_ebit_latest = df_ebit_latest.set_index(\"symbol\", drop=True)\n",
    "\n",
    "df_results[\"EBIT margin\"] = df_ebit_latest.apply(calculate_ebit_margin, axis=1)\n",
    "df_ebit_latest[\"Score EBIT margin\"] = df_ebit_latest.apply(calculate_ebit_margin, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Punkte für EK-Quote\n",
    "# Wenn >25% dann +1, wenn <15% dann -1, sonst 0\n",
    "\n",
    "# Funktion zur Bewertung:\n",
    "def calculate_equity_ratio(row):\n",
    "    common_stock = row[\"CommonStockEquity\"]\n",
    "    assets = row[\"TotalAssets\"]\n",
    "    if (common_stock is None) | (assets is None):\n",
    "        return \"keine Daten\"\n",
    "    elif (common_stock/assets) > 0.25:\n",
    "        return 1\n",
    "    elif (common_stock/assets) >= 0.15 and (common_stock/assets) <= 0.25:\n",
    "        return 0\n",
    "    elif (common_stock/assets) < 0.15:\n",
    "       return -1\n",
    "\n",
    "# Sortiere das Dataframe Fundamentals nach Datum, um im nächsten Schritt jeweils den aktuellsten vollständigen Eintrag zu wählen\n",
    "df_equity_ratio_sorted = []\n",
    "df_equity_ratio_sorted = df_fundamentals.sort_values(\"asOfDate\", ascending=False)\n",
    "\n",
    "# Gruppiere das Dataframe nach dem Symbol und wähle die erste Zeile für jedes Symbol aus\n",
    "df_equity_ratio_latest = df_equity_ratio_sorted.groupby(\"symbol\").first().reset_index()\n",
    "df_equity_ratio_latest = df_equity_ratio_latest.set_index(\"symbol\", drop=True)\n",
    "\n",
    "df_results[\"equity ratio\"] = df_ebit_latest.apply(calculate_equity_ratio, axis=1)\n",
    "df_ebit_latest[\"Score equity ratio\"] = df_ebit_latest.apply(calculate_equity_ratio, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Punkte für 5-Jahres-KGV\n",
    "# letzte 3 Jahre, aktuelles Geschäftsjahr, nächstes Geschäftsjahr\n",
    "# Wenn <12 dann +1, wenn >16 oder <0 dann -1, sonst 0\n",
    "df_pe_ratio_5 = pd.DataFrame()\n",
    "\n",
    "df_pe_ratio_5 = df_fundamentals[df_fundamentals[\"periodType\"] == \"12M\"][[\"symbol\", \"asOfDate\", \"DilutedEPS\"]]\n",
    "df_pe_ratio_5 = df_pe_ratio_5.sort_values(\"asOfDate\", ascending=False)\n",
    "df_pe_5_agg = df_pe_ratio_5.groupby(\"symbol\").head(3)\n",
    "\n",
    "# Dataframe mit den prognostizierten EPS des aktuellen/kommenden Jahres:\n",
    "df_pe_future = df_earnings_future[[\"symbol\", \"period\", \"epsTrend_current\"]]\n",
    "df_pe_future = df_pe_future.rename(columns={\"period\": \"asOfDate\", \"epsTrend_current\": \"DilutedEPS\"})\n",
    "\n",
    "# Dataframes zusammenführen und EPS addieren\n",
    "df_pe_5_agg = pd.concat([df_pe_5_agg, df_pe_future])\n",
    "df_pe_5_agg = df_pe_5_agg.groupby(\"symbol\").agg({\"DilutedEPS\": \"sum\", \"symbol\": \"count\"}).rename(columns={\"symbol\": \"Count\"})\n",
    "\n",
    "# Ermitteln des aktuellsten Kurses\n",
    "df_prices_pe = df_kurse\n",
    "df_prices_pe = df_prices_pe.sort_values(\"date\", ascending=False)\n",
    "df_prices_pe = df_prices_pe.groupby(\"symbol\").first().reset_index()\n",
    "df_prices_pe = df_prices_pe.set_index(\"symbol\", drop=True)\n",
    "df_prices_pe = df_prices_pe[[\"date\", \"close\"]]\n",
    "df_prices_pe[\"date\"] = pd.to_datetime(df_prices_pe[\"date\"]).dt.strftime('%Y-%m-%d')\n",
    "df_prices_pe = df_prices_pe.rename(columns={\"close\": \"previous close\"})\n",
    "\n",
    "df_pe_5_results = pd.merge(df_pe_5_agg, df_prices_pe, left_index=True, right_index=True, how=\"inner\")\n",
    "\n",
    "def calculate_pe_ratio(row):\n",
    "    price = row[\"previous close\"]\n",
    "    earnings = row[\"DilutedEPS\"]\n",
    "    count = row[\"Count\"]\n",
    "    if count == 0:\n",
    "        return \"keine Daten\"\n",
    "    elif ((price * count)/earnings) < 12:\n",
    "        return 1\n",
    "    elif ((price * count)/earnings) >= 12 and ((price * count)/earnings) <= 16:\n",
    "        return 0\n",
    "    elif ((price * count)/earnings) > 16:\n",
    "        return -1\n",
    "    elif ((price * count)/earnings) < 0:\n",
    "        return -1\n",
    "    \n",
    "df_results[\"pe_ratio_5yr\"] = df_pe_5_results.apply(calculate_pe_ratio, axis=1)\n",
    "df_pe_5_results[\"Score pe_ratio_5yr\"] = df_pe_5_results.apply(calculate_pe_ratio, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Punkte für aktuelles KGV\n",
    "# Wenn <12 dann +1, wenn >16 oder <0 dann -1, sonst 0\n",
    "df_pe_ratio_current = pd.DataFrame()\n",
    "df_pe_future = pd.DataFrame()\n",
    "df_prices_pe_current = pd.DataFrame()\n",
    "df_pe_current_results = pd.DataFrame()\n",
    "\n",
    "df_pe_ratio_current = df_fundamentals[df_fundamentals[\"periodType\"] == \"12M\"][[\"symbol\", \"asOfDate\", \"DilutedEPS\"]]\n",
    "df_pe_ratio_current = df_pe_ratio_current.sort_values(\"asOfDate\", ascending=False)\n",
    "df_pe_ratio_current = df_pe_ratio_current.groupby(\"symbol\").first()\n",
    "df_pe_ratio_current = df_pe_ratio_current.rename(columns={\"DilutedEPS\": \"EPS_last\"})\n",
    "\n",
    "# Dataframe mit den prognostizierten EPS des aktuellen/kommenden Jahres:\n",
    "df_pe_current_future = df_earnings_future[df_earnings_future[\"period\"] == \"0y\"][[\"symbol\", \"period\", \"epsTrend_current\"]]\n",
    "df_pe_current_future = df_pe_current_future.rename(columns={\"period\": \"asOfDate\", \"epsTrend_current\": \"DilutedEPS\"})\n",
    "df_pe_current_future = df_pe_current_future.set_index(df_pe_current_future[\"symbol\"])\n",
    "df_pe_current_future = df_pe_current_future.rename(columns={\"DilutedEPS\": \"EPS_current\"})\n",
    "\n",
    "# Ermitteln des aktuellsten Kurses\n",
    "df_prices_pe_current = df_kurse\n",
    "df_prices_pe_current = df_prices_pe_current.sort_values(\"date\", ascending=False)\n",
    "df_prices_pe_current = df_prices_pe_current.groupby(\"symbol\").first().reset_index()\n",
    "df_prices_pe_current = df_prices_pe_current.set_index(\"symbol\", drop=True)\n",
    "df_prices_pe_current = df_prices_pe_current[[\"date\", \"close\"]]\n",
    "df_prices_pe_current[\"date\"] = pd.to_datetime(df_prices_pe_current[\"date\"]).dt.strftime('%Y-%m-%d')\n",
    "df_prices_pe_current = df_prices_pe_current.rename(columns={\"close\": \"previous close\"})\n",
    "\n",
    "# Data Frames zusammenführen für die Funktion\n",
    "df_pe_current_results = pd.merge(df_pe_ratio_current, df_pe_current_future, left_index=True, right_index=True, how=\"inner\")\n",
    "df_pe_current_results = pd.merge(df_pe_current_results, df_prices_pe_current, left_index=True, right_index=True, how=\"inner\")\n",
    "df_pe_current_results = df_pe_current_results.set_index(df_pe_current_results[\"symbol\"])\n",
    "\n",
    "def calculate_pe_ratio_current(row):\n",
    "    price = row[\"previous close\"]\n",
    "    earnings_current = row[\"EPS_current\"]\n",
    "    earnings_past = row[\"EPS_last\"]\n",
    "    if (earnings_current is None) | (earnings_current == 0) | (earnings_current == \"\"):\n",
    "        if (earnings_past is None) | (earnings_past == 0) | (earnings_past == \"\"):\n",
    "            return \"keine Daten\"\n",
    "        elif (price/earnings_past) < 12:\n",
    "            return 1\n",
    "        elif (price/earnings_past) >= 12 and (price/earnings_past) <= 16:\n",
    "            return 0\n",
    "        elif (price/earnings_past) > 16:\n",
    "            return -1\n",
    "    elif (price/earnings_current) < 12:\n",
    "        return 1\n",
    "    elif (price/earnings_current) >= 12 and (price/earnings_current) <= 16:\n",
    "        return 0\n",
    "    elif (price/earnings_current) > 16:\n",
    "        return -1\n",
    "    elif (price/earnings_current) < 0:\n",
    "        return -1\n",
    "    \n",
    "df_results[\"pe_ratio_current\"] = df_pe_current_results.apply(calculate_pe_ratio_current, axis=1)\n",
    "df_pe_current_results[\"Score pe_ratio_current\"] = df_pe_current_results.apply(calculate_pe_ratio_current, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Punkte für Analystenmeinungen\n",
    "# Wenn Anzahl <5 und Meinung <2 dann 1, \n",
    "# wenn Anzahl <5 und Meinung zwischen 2 und 4 dann 0,\n",
    "# wenn Anzahl <5 und Meinung >4 dann -1,\n",
    "# wenn Anzahl >5 und Meinung >4 dann 1,\n",
    "# wenn Anzahl >5 und Meinung zwischen 2 und 4 dann 0\n",
    "# wenn Anzahl >5 und Meinung <2 dann -1\n",
    "\n",
    "def calculate_analysts(row):\n",
    "    valuation = row[\"recommendationMean\"]\n",
    "    count = row[\"numberOfAnalystOpinions\"]\n",
    "    if (count is None) | (valuation is None):\n",
    "        return \"keine Daten\"\n",
    "    elif (count < 5) and (valuation <2):\n",
    "        return 1\n",
    "    elif (count < 5) and (valuation >= 2) and (valuation <=4):\n",
    "        return 0\n",
    "    elif (count < 5) and (valuation > 4):\n",
    "        return -1\n",
    "    elif (count > 5) and (valuation > 4):\n",
    "        return 1\n",
    "    elif (count > 5) and (valuation >= 2) and (valuation <= 4):\n",
    "        return 0\n",
    "    elif (count > 5) and (valuation < 2):\n",
    "        return -1\n",
    "        \n",
    "df_results[\"analysts_opinion\"] = df_analysts.apply(calculate_analysts, axis=1)\n",
    "df_analysts[\"Score analysts_opinion\"] = df_analysts.apply(calculate_analysts, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Punkte für Quartalszahlen\n",
    "# Punkte Quartalszahlen: +1 wenn Differenz Entwicklung (nach letzten Earnings) >1%, -1 wenn Differenz Entwicklung <-1%, sonst 0\n",
    "# Entwicklung Kurs letzte Earnings ((Kurs nach Earnings - Kurs Vortag) / Kurs Vortag)\n",
    "# Entwicklung Kurs Benchmark (analog dazu)\n",
    "# Differenz Entwicklung (Entw. Kurs - Entw. Benchmark)\n",
    "\n",
    "df_history_announcements = pd.DataFrame()\n",
    "df_latest_announcement = pd.DataFrame()\n",
    "\n",
    "# Ermittlung der Daten der letzten Quartalszahlen\n",
    "df_latest_announcement = df_dates\n",
    "df_latest_announcement = df_latest_announcement.sort_values(\"Dates\", ascending=False)\n",
    "df_latest_announcement = df_latest_announcement.groupby(\"symbol\").first()\n",
    "\n",
    "df_prices[\"date\"] = pd.to_datetime(df_prices[\"date\"])\n",
    "df_latest_announcement[\"Dates\"] = pd.to_datetime(df_latest_announcement[\"Dates\"])\n",
    "df_latest_announcement[\"announcement_next_trading_day\"] = df_latest_announcement[\"Dates\"].apply(get_next_trading_day)\n",
    "\n",
    "df_latest_announcement[\"post date\"] = pd.to_datetime(df_latest_announcement[\"Dates\"]) + pd.DateOffset(days = 1)\n",
    "df_latest_announcement[\"post date\"] = df_latest_announcement[\"post date\"].apply(get_next_trading_day)\n",
    "df_latest_announcement[\"post date\"] = pd.to_datetime(df_latest_announcement[\"post date\"])\n",
    "df_latest_announcement = df_latest_announcement.rename(columns={\"announcement_next_trading_day\": \"date\"})\n",
    "df_latest_announcement.drop(columns=[\"Dates\"])\n",
    "\n",
    "# Anfügen der Kurse von Asset und Benchmark zu Datum der letzten Earnings\n",
    "df_history_announcements = pd.merge(df_latest_announcement, df_prices, how=\"left\", left_on=[\"symbol\", \"date\"], right_on=[\"symbol\", \"date\"])\n",
    "df_history_announcements = pd.merge(df_history_announcements, df_prices, how=\"left\", left_on=[\"symbol\", \"post date\"], right_on=[\"symbol\", \"date\"], suffixes=(\"\", \"_post\"))\n",
    "df_history_announcements = df_history_announcements.drop_duplicates()\n",
    "df_history_announcements = df_history_announcements.set_index(\"symbol\", drop=False)\n",
    "df_history_announcements = df_history_announcements[~df_history_announcements.index.duplicated(keep='first')]\n",
    "\n",
    "# Bewertungsfunktion\n",
    "def calculate_eps_reaction(row):\n",
    "    symbol = row[\"symbol\"]\n",
    "    benchmark = row[\"benchmark\"]\n",
    "    benchmark_check = row[\"benchmark_post\"]\n",
    "    date_post = row[\"post date\"]\n",
    "    date_check = row[\"date_post\"]\n",
    "    date_announcement = row[\"date\"]\n",
    "    price_asset = row[\"previous close\"]\n",
    "    price_benchmark = row[\"previous close_benchmark\"]\n",
    "    price_asset_post = row[\"previous close_post\"]\n",
    "    price_benchmark_post = row[\"previous close_benchmark_post\"]\n",
    "    reaction_asset = (price_asset_post - price_asset) / price_asset\n",
    "    reaction_benchmark = (price_benchmark_post - price_benchmark) / price_benchmark\n",
    "    delta_reaction = reaction_asset - reaction_benchmark\n",
    "    if (symbol is None) | (benchmark is None) | (date_post is None) | (date_announcement is None) | (benchmark != benchmark_check) | (date_post != date_check) | (date_post <= date_announcement) | (delta_reaction is None):\n",
    "        return \"keine Daten\"\n",
    "    elif delta_reaction > 0.01:\n",
    "        return 1\n",
    "    elif (delta_reaction <= 0.01) and (delta_reaction >= -0.01):\n",
    "        return 0\n",
    "    elif delta_reaction < -0.01:\n",
    "        return -1\n",
    "\n",
    "df_results[\"earnings reaction\"] = df_history_announcements.apply(calculate_eps_reaction, axis=1)\n",
    "df_history_announcements[\"Score earnings reaction\"] = df_history_announcements.apply(calculate_eps_reaction, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Punkte für Revision der Ergebnisse\n",
    "# Revision EPS AJ (Delta EPS zu vor 4 Wochen, falls möglich, ansonsten nimm den Wert von vor 2 Wochen) geteilt durch den Wert vor 4 bzw. 2 Wochen\n",
    "# Revision EPS NJ (analog dazu)\n",
    "# Punkte Revision EPS (für beide Quellen jeweils separat): wenn entweder Revision EPS AJ oder NJ leer ist, nur das andere betrachten: \n",
    "# +1 wenn Revision EPS NJ >5%, -1 wenn Revision EPS <-5%. Wenn beide gefüllt sind: Punkte der beiden saldieren, +2 bzw. -2 werden zu +1 bzw. -1. Sonst 0\n",
    "\n",
    "df_revisions = pd.DataFrame()\n",
    "df_revisions_0y = pd.DataFrame()\n",
    "df_revisions_1y = pd.DataFrame()\n",
    "df_revisions_tmp = pd.DataFrame()\n",
    "\n",
    "# Daten abfragen und in 2 separate Dataframes (aktuelles Jahr und kommendes Jahr) einfügen\n",
    "df_revisions = df_earnings_future[[\"symbol\", \"period\", \"epsTrend_current\", \"epsTrend_7daysAgo\", \"epsTrend_30daysAgo\"]]\n",
    "df_revisions_0y = df_revisions[df_revisions[\"period\"] == \"0y\"]\n",
    "df_revisions_1y = df_revisions[df_revisions[\"period\"] == \"+1y\"]\n",
    "\n",
    "df_revisions_0y = df_revisions_0y.set_index(\"symbol\")\n",
    "df_revisions_1y = df_revisions_1y.set_index(\"symbol\")\n",
    "\n",
    "def calculate_revisions(row):\n",
    "    period = row[\"period\"]\n",
    "    epsToday = row[\"epsTrend_current\"]\n",
    "    epsOld = row[\"epsTrend_30daysAgo\"]\n",
    "    if (epsOld == 0) | (epsOld == \"\"):\n",
    "        return \"Division durch Null (EPS alt = Null)\"\n",
    "    elif (period != \"0y\" and period != \"+1y\"):\n",
    "        return \"keine Daten\"\n",
    "    elif ((epsToday - epsOld) / epsOld) > 0.05:\n",
    "        return 1\n",
    "    elif (((epsToday - epsOld) / epsOld) <= 0.05) and (((epsToday - epsOld) / epsOld) >= -0.05):\n",
    "        return 0\n",
    "    elif ((epsToday - epsOld) / epsOld) < -0.05:\n",
    "        return -1\n",
    "\n",
    "def calculate_revisions_alternative(row):\n",
    "    period = row[\"period\"]\n",
    "    epsToday = row[\"epsTrend_current\"]\n",
    "    epsOld = row[\"epsTrend_7daysAgo\"]\n",
    "    if (epsOld == 0) | (epsOld == \"\"):\n",
    "        return \"Division durch Null (EPS alt = Null)\"\n",
    "    elif (period != \"0y\" and period != \"+1y\"):\n",
    "        return \"keine Daten\"\n",
    "    elif ((epsToday - epsOld) / epsOld) > 0.05:\n",
    "        return 1\n",
    "    elif (((epsToday - epsOld) / epsOld) <= 0.05) and (((epsToday - epsOld) / epsOld) >= -0.05):\n",
    "        return 0\n",
    "    elif ((epsToday - epsOld) / epsOld) < -0.05:\n",
    "        return -1\n",
    "\n",
    "# Punkte aufaddieren für aktuelles und für nächstes Jahr\n",
    "df_revisions_tmp[\"Rev_0y\"] = df_revisions_0y.apply(calculate_revisions, axis=1)\n",
    "df_revisions_tmp[\"Rev_0y_alt\"] = df_revisions_0y.apply(calculate_revisions_alternative, axis=1)\n",
    "df_revisions_tmp[\"Rev_1y\"] = df_revisions_1y.apply(calculate_revisions, axis=1)\n",
    "df_revisions_tmp[\"Rev_1y_alt\"] = df_revisions_1y.apply(calculate_revisions_alternative, axis=1)\n",
    "\n",
    "# Bewerten\n",
    "def add_rev_values(row):\n",
    "    rev_0y = row[\"Rev_0y\"]\n",
    "    rev_1y = row[\"Rev_1y\"]\n",
    "    rev_0y_alt = row[\"Rev_0y_alt\"]\n",
    "    rev_1y_alt = row[\"Rev_1y_alt\"]\n",
    "    if rev_0y is None or pd.isnull(rev_0y) or pd.isna(rev_0y) or rev_0y == \"\":\n",
    "        if rev_1y is None or pd.isnull(rev_1y) or pd.isna(rev_1y) or rev_1y == \"\":\n",
    "            if rev_0y_alt is None or pd.isnull(rev_0y_alt) or pd.isna(rev_0y_alt) or rev_0y_alt == \"\":\n",
    "                if rev_1y_alt is None or pd.isnull(rev_1y_alt) or pd.isna(rev_1y_alt) or rev_1y_alt == \"\":\n",
    "                    result = \"keine Daten\"\n",
    "                else:\n",
    "                    result = rev_1y_alt\n",
    "            else:\n",
    "                result = rev_0y_alt\n",
    "        else:\n",
    "            result = rev_1y\n",
    "    else:\n",
    "        result = rev_0y         \n",
    "    if result == 2:\n",
    "        result = 1\n",
    "    elif result == -2:\n",
    "        result = -1 \n",
    "    return result\n",
    "\n",
    "df_revisions_tmp[\"earnings revisions\"] = df_revisions_tmp.apply(add_rev_values, axis=1)\n",
    "\n",
    "df_results = pd.merge(df_results, df_revisions_tmp[\"earnings revisions\"], how=\"left\", left_index=True, right_index=True,)\n",
    "df_revisions = df_revisions_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Punkte 6-Monats-Entwicklung\n",
    "# Punkte 6 Monate: +1 wenn relative Performance 6 Monate >5%, -1 wenn relative Performance 6 Monate <-5%, sonst 0\n",
    "# Entwicklung Kurs Asset und Kurs Benchmark seit 6 Monaten ((letzter Kurs - Kurs vor 6 Monaten) / Kurs vor 6 Monaten)\n",
    "# Differenz Entwicklung (Entw. Kurs - Entw. Benchmark)\n",
    "\n",
    "df_6months_ago = pd.DataFrame()\n",
    "df_latest_prices = pd.DataFrame()\n",
    "\n",
    "# Ermittlung der aktuellsten Kurse\n",
    "df_latest_prices = df_prices\n",
    "df_latest_prices = df_latest_prices.sort_values(\"date\", ascending=False)\n",
    "df_latest_prices = df_latest_prices.groupby(\"symbol\").first()\n",
    "df_latest_prices[\"date\"] = pd.to_datetime(df_latest_prices[\"date\"]).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Ermittlung der Kurse vor 6 Monaten (bzw. am darauffolgenden nächsten verfügbaren Kurs)\n",
    "df_6months_ago = df_prices\n",
    "date_6months = df_previous_days.loc[df_previous_days[\"Description\"] == \"vor 6 Monaten\", \"Dates\"].values[0]\n",
    "date_6months = pd.to_datetime(date_6months).strftime('%Y-%m-%d')\n",
    "df_6months_ago = df_6months_ago[df_6months_ago[\"date\"] == date_6months]\n",
    "# Überprüfung, ob Eintrag am vorliegenden Datum vorhanden ist\n",
    "while df_6months_ago.empty:\n",
    "    # Einen Tag zurückgehen\n",
    "    date_6months -= dt.timedelta(days=1)\n",
    "    df_6months_ago = df_prices[df_prices[\"date\"] == date_6months]\n",
    "\n",
    "df_6months_ago = df_6months_ago.drop_duplicates()\n",
    "df_6months_ago = df_6months_ago.set_index(\"symbol\")\n",
    "\n",
    "df_6_months_comparison = pd.merge(df_6months_ago, df_latest_prices, how=\"left\", left_index=True, right_index=True, suffixes=(\"_6months\",\"_current\"))\n",
    "\n",
    "# Bewertungsfunktion\n",
    "def calculate_6_months_performance(row):\n",
    "    benchmark = row[\"benchmark_6months\"]\n",
    "    benchmark_check = row[\"benchmark_current\"]\n",
    "    date = row[\"date_6months\"]\n",
    "    date_check = row[\"date_current\"]\n",
    "    price_asset_old = row[\"previous close_6months\"]\n",
    "    price_benchmark_old = row[\"previous close_benchmark_6months\"]\n",
    "    price_asset_new = row[\"previous close_current\"]\n",
    "    price_benchmark_new = row[\"previous close_benchmark_current\"]\n",
    "    performance_asset = (price_asset_new - price_asset_old) / price_asset_old\n",
    "    performance_benchmark = (price_benchmark_new - price_benchmark_old) / price_benchmark_old\n",
    "    delta_performance = performance_asset - performance_benchmark\n",
    "    if (date is None) | (price_asset_new is None) | (price_asset_new == 0) | (price_benchmark_new is None) | (price_benchmark_new == 0) | (date_check is None) | (benchmark is None) | (benchmark != benchmark_check) | (date >= pd.to_datetime(date_check)) | (delta_performance is None):\n",
    "        return \"keine Daten\"\n",
    "    elif delta_performance > 0.05:\n",
    "        return 1\n",
    "    elif (delta_performance <= 0.05) and (delta_performance >= -0.05):\n",
    "        return 0\n",
    "    elif delta_performance < -0.05:\n",
    "        return -1\n",
    "\n",
    "df_results[\"6 months performance\"] = df_6_months_comparison.apply(calculate_6_months_performance, axis=1)\n",
    "df_6_months_comparison[\"Score 6 months performance\"] = df_6_months_comparison.apply(calculate_6_months_performance, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Punkte 1-Jahres-Entwicklung\n",
    "# Punkte 1 Jahr: +1 wenn relative Performance 1 Jahr >5%, -1 wenn relative Performance 1 Jahr <-5%, sonst 0\n",
    "# Entwicklung Kurs Asset und Kurs Benchmark seit 1 Jahr ((letzter Kurs - Kurs vor 1 Jahr) / Kurs vor 1 Jahr)\n",
    "# Differenz Entwicklung (Entw. Kurs - Entw. Benchmark)\n",
    "\n",
    "df_1year_ago = pd.DataFrame()\n",
    "df_latest_prices = pd.DataFrame()\n",
    "\n",
    "# Ermittlung der aktuellsten Kurse\n",
    "df_latest_prices = df_prices\n",
    "df_latest_prices = df_latest_prices.sort_values(\"date\", ascending=False)\n",
    "df_latest_prices = df_latest_prices.groupby(\"symbol\").first()\n",
    "df_latest_prices[\"date\"] = pd.to_datetime(df_latest_prices[\"date\"])\n",
    "\n",
    "# Ermittlung der Kurse vor 6 Monaten (bzw. am darauffolgenden nächsten verfügbaren Kurs)\n",
    "df_1year_ago = df_prices\n",
    "date_1year = df_previous_days.loc[df_previous_days[\"Description\"] == \"vor 1 Jahr\", \"Dates\"].values[0]\n",
    "date_1year = pd.to_datetime(date_1year)\n",
    "df_1year_ago = df_1year_ago[df_1year_ago[\"date\"] == date_1year]\n",
    "# Überprüfung, ob Eintrag am vorliegenden Datum vorhanden ist\n",
    "while df_1year_ago.empty:\n",
    "    # Einen Tag zurückgehen\n",
    "    date_1year -= dt.timedelta(days=1)\n",
    "    df_1year_ago = df_prices[df_prices[\"date\"] == date_1year]\n",
    "\n",
    "df_1year_ago = df_1year_ago.drop_duplicates()\n",
    "df_1year_ago = df_1year_ago.set_index(\"symbol\")\n",
    "\n",
    "df_1_year_comparison = pd.merge(df_1year_ago, df_latest_prices, how=\"left\", left_index=True, right_index=True, suffixes=(\"_1year\",\"_current\"))\n",
    "\n",
    "# Bewertungsfunktion\n",
    "def calculate_1_year_performance(row):\n",
    "    benchmark = row[\"benchmark_1year\"]\n",
    "    benchmark_check = row[\"benchmark_current\"]\n",
    "    date = row[\"date_1year\"]\n",
    "    date_check = row[\"date_current\"]\n",
    "    price_asset_old = row[\"previous close_1year\"]\n",
    "    price_benchmark_old = row[\"previous close_benchmark_1year\"]\n",
    "    price_asset_new = row[\"previous close_current\"]\n",
    "    price_benchmark_new = row[\"previous close_benchmark_current\"]\n",
    "    performance_asset = (price_asset_new - price_asset_old) / price_asset_old\n",
    "    performance_benchmark = (price_benchmark_new - price_benchmark_old) / price_benchmark_old\n",
    "    delta_performance = performance_asset - performance_benchmark\n",
    "    if (date is None) | (price_asset_new is None) | (price_asset_new == 0) | (price_benchmark_new is None) | (price_benchmark_new == 0) | (date_check is None) | (benchmark is None) | (benchmark != benchmark_check) | (date >= date_check) | (delta_performance is None):\n",
    "        return \"keine Daten\"\n",
    "    elif delta_performance > 0.05:\n",
    "        return 1\n",
    "    elif (delta_performance <= 0.05) and (delta_performance >= -0.05):\n",
    "        return 0\n",
    "    elif delta_performance < -0.05:\n",
    "        return -1\n",
    "\n",
    "df_results[\"1 year performance\"] = df_1_year_comparison.apply(calculate_1_year_performance, axis=1)\n",
    "df_1_year_comparison[\"Score 1 year performance\"] = df_1_year_comparison.apply(calculate_1_year_performance, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Punkte Momentum \n",
    "# +1 wenn Punkte 6 Monate = +1 UND Punkte 1 Jahr = 0 oder -1, \n",
    "# 0 wenn Punkte 6 Monate = 0 ODER wenn (Punkte 6 Monate = +1 UND Punkt 1 Jahr = +1) ODER wenn (Punkte 6 Monate = -1 UND Punkte 1 Jahr = -1)\n",
    "# -1 wenn Punkte 6 Monate = -1 UND Punkte 1 Jahr = 0 oder +1, \n",
    "\n",
    "# Voraussetzung ist, dass sowohl Punkte 6 Monate und Punkte 1 Jahr ermittelt wurden.\n",
    "\n",
    "df_momentum = pd.DataFrame()\n",
    "df_momentum[[\"6 months performance\", \"1 year performance\"]] = df_results[[\"6 months performance\", \"1 year performance\"]]\n",
    "\n",
    "# Bewertungsfunktion\n",
    "def calculate_momentum(row):\n",
    "    new = row[\"6 months performance\"]\n",
    "    old = row[\"1 year performance\"]\n",
    "    if (new is None) | (old is None) | (new == \"keine Daten\") | (old == \"keine Daten\"):\n",
    "        return \"keine Daten\"\n",
    "    elif (new == 1) and ((old == 0) | (old == -1)):\n",
    "      return 1\n",
    "    elif (new == 0) | ((new == 1) and (old == 1)) | ((new == -1) and (old == -1)):\n",
    "        return 0\n",
    "    elif (new == -1) and ((old == 1) | (old == 0)):\n",
    "        return -1\n",
    "\n",
    "df_results[\"momentum\"] = df_momentum.apply(calculate_momentum, axis= 1)\n",
    "df_momentum[\"Score momentum\"] = df_momentum.apply(calculate_momentum, axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Punkte für Dreimonatsreversal\n",
    "# +1 Punkt wenn Performance des Assets in den vergangenen 3 1-Monats-Zeiträumen jedes Mal schlechter als der Vergleichsindex war\n",
    "# -1 Punkt wenn Performance des Assets in den vergangenen 3 1-Monats-Zeiträumen jedes Mal besser als der Vergleichsindex war\n",
    "# Sonst 0 Punkte\n",
    "\n",
    "df_1to3_months_ago = pd.DataFrame()\n",
    "df_latest_prices = pd.DataFrame()\n",
    "df_1to3_months_tmp1 = pd.DataFrame()\n",
    "df_1to3_months_tmp2 = pd.DataFrame()\n",
    "df_1to3_months_comparison = pd.DataFrame()\n",
    "df_1month_ago = pd.DataFrame()\n",
    "df_2months_ago = pd.DataFrame()\n",
    "df_3months_ago = pd.DataFrame()\n",
    "\n",
    "# Ermittlung der aktuellsten Kurse\n",
    "df_latest_prices = df_prices\n",
    "df_latest_prices = df_latest_prices.sort_values(\"date\", ascending=False)\n",
    "df_latest_prices = df_latest_prices.groupby(\"symbol\").first()\n",
    "df_latest_prices[\"date\"] = pd.to_datetime(df_latest_prices[\"date\"])\n",
    "\n",
    "# Ermittlung der Kurse vor 1 Monat (bzw. am darauffolgenden nächsten verfügbaren Kurs)\n",
    "df_1month_ago = df_prices\n",
    "date_1month = df_previous_days.loc[df_previous_days[\"Description\"] == \"vor 1 Monat\", \"Dates\"].values[0]\n",
    "date_1month = pd.to_datetime(date_1month)\n",
    "df_1month_ago = df_1month_ago[df_1month_ago[\"date\"] == date_1month]\n",
    "# Überprüfung, ob Eintrag am vorliegenden Datum vorhanden ist\n",
    "while df_1month_ago.empty:\n",
    "    # Einen Tag zurückgehen\n",
    "    date_1month -= dt.timedelta(days=1)\n",
    "    df_1month_ago = df_prices[df_prices[\"date\"] == date_1month]\n",
    "df_1month_ago = df_1month_ago.drop_duplicates()\n",
    "df_1month_ago = df_1month_ago.set_index(\"symbol\")\n",
    "\n",
    "# Ermittlung der Kurse vor 2 Monaten (bzw. am darauffolgenden nächsten verfügbaren Kurs)\n",
    "df_2months_ago = df_prices\n",
    "date_2months = df_previous_days.loc[df_previous_days[\"Description\"] == \"vor 2 Monaten\", \"Dates\"].values[0]\n",
    "date_2months = pd.to_datetime(date_2months)\n",
    "df_2months_ago = df_2months_ago[df_2months_ago[\"date\"] == date_2months]\n",
    "# Überprüfung, ob Eintrag am vorliegenden Datum vorhanden ist\n",
    "while df_2months_ago.empty:\n",
    "    # Einen Tag zurückgehen\n",
    "    date_2months -= dt.timedelta(days=1)\n",
    "    df_2months_ago = df_prices[df_prices[\"date\"] == date_2months]\n",
    "df_2months_ago = df_2months_ago.drop_duplicates()\n",
    "df_2months_ago = df_2months_ago.set_index(\"symbol\")\n",
    "\n",
    "# Ermittlung der Kurse vor 3 Monaten (bzw. am darauffolgenden nächsten verfügbaren Kurs)\n",
    "df_3months_ago = df_prices\n",
    "date_3months = df_previous_days.loc[df_previous_days[\"Description\"] == \"vor 3 Monaten\", \"Dates\"].values[0]\n",
    "date_3months = pd.to_datetime(date_3months)\n",
    "df_3months_ago = df_3months_ago[df_3months_ago[\"date\"] == date_3months]\n",
    "# Überprüfung, ob Eintrag am vorliegenden Datum vorhanden ist\n",
    "while df_3months_ago.empty:\n",
    "    # Einen Tag zurückgehen\n",
    "    date_3months -= dt.timedelta(days=1)\n",
    "    df_3months_ago = df_prices[df_prices[\"date\"] == date_3months]\n",
    "df_3months_ago = df_3months_ago.drop_duplicates()\n",
    "df_3months_ago = df_3months_ago.set_index(\"symbol\")\n",
    "\n",
    "# Zusammenführen der Dataframes\n",
    "df_1to3_months_tmp1 = pd.merge(df_latest_prices, df_1month_ago, how=\"left\", left_index=True, right_index=True, suffixes=(\"\",\"_1month\"))\n",
    "df_1to3_months_tmp2 = pd.merge(df_1to3_months_tmp1, df_2months_ago, how=\"left\", left_index=True, right_index=True, suffixes=(\"\",\"_2months\"))\n",
    "df_1to3_months_comparison = pd.merge(df_1to3_months_tmp2, df_3months_ago, how=\"left\", left_index=True, right_index=True, suffixes=(\"\",\"_3months\"))\n",
    "\n",
    "# Bewertungsfunktion\n",
    "def calculate_1to3_months_performance(row):\n",
    "    symbol_benchmark_now = row[\"benchmark\"]\n",
    "    symbol_benchmark_1m = row[\"benchmark_1month\"]\n",
    "    symbol_benchmark_2m = row[\"benchmark_2months\"]\n",
    "    symbol_benchmark_3m = row[\"benchmark_3months\"]\n",
    "    date_now = row[\"date\"]\n",
    "    date_1m = row[\"date_1month\"]\n",
    "    date_2m = row[\"date_2months\"]\n",
    "    date_3m = row[\"date_3months\"]\n",
    "    asset_now = row[\"previous close\"]\n",
    "    asset_1m = row[\"previous close_1month\"]\n",
    "    asset_2m = row[\"previous close_2months\"]\n",
    "    asset_3m = row[\"previous close_3months\"]\n",
    "    benchmark_now = row[\"previous close_benchmark\"]\n",
    "    benchmark_1m = row[\"previous close_benchmark_1month\"]\n",
    "    benchmark_2m = row[\"previous close_benchmark_2months\"]\n",
    "    benchmark_3m = row[\"previous close_benchmark_3months\"]\n",
    "    perf_asset_now = (asset_now - asset_1m) / asset_1m\n",
    "    perf_asset_1m = (asset_1m - asset_2m) / asset_2m\n",
    "    perf_asset_2m = (asset_2m - asset_3m) / asset_3m\n",
    "    perf_benchmark_now = (benchmark_now - benchmark_1m) / benchmark_1m\n",
    "    perf_benchmark_1m = (benchmark_1m - benchmark_2m) / benchmark_2m\n",
    "    perf_benchmark_2m = (benchmark_2m - benchmark_3m) / benchmark_3m\n",
    "    delta_perf_now = perf_asset_now - perf_benchmark_now\n",
    "    delta_perf_1m = perf_asset_1m - perf_benchmark_1m\n",
    "    delta_perf_2m = perf_asset_2m - perf_benchmark_2m\n",
    "    if any(x is None or pd.isnull(x) or pd.isna(x) or x == \"\" for x in (symbol_benchmark_now, \n",
    "                                                                        symbol_benchmark_1m, \n",
    "                                                                        symbol_benchmark_2m, \n",
    "                                                                        symbol_benchmark_3m, \n",
    "                                                                        date_now, \n",
    "                                                                        date_1m, \n",
    "                                                                        date_2m, \n",
    "                                                                        date_3m, \n",
    "                                                                        asset_now, \n",
    "                                                                        asset_1m, \n",
    "                                                                        asset_2m, \n",
    "                                                                        asset_3m, \n",
    "                                                                        benchmark_now, \n",
    "                                                                        benchmark_1m, \n",
    "                                                                        benchmark_2m, \n",
    "                                                                        benchmark_3m\n",
    "                                                                        )):\n",
    "        return \"keine Daten\"\n",
    "    elif any(x > 0 for x in (delta_perf_now, delta_perf_1m, delta_perf_2m)):\n",
    "        return -1\n",
    "    elif any(x < 0 for x in (delta_perf_now, delta_perf_1m, delta_perf_2m)):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df_results[\"3 months reversal\"] = df_1to3_months_comparison.apply(calculate_1to3_months_performance, axis= 1)\n",
    "df_1to3_months_comparison[\"Score 3 months reversal\"] = df_1to3_months_comparison.apply(calculate_1to3_months_performance, axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Punkte Gewinnwachstum\n",
    "# Gewinnwachstum +1 wenn Gewinnwachstum >5%, -1 wenn Gewinnwachstum <-5%, sonst 0\n",
    "# wenn EPS AJ UND EPS NJ <>0 UND EPS AJ >0, dann (EPS NJ - EPS AJ)/EPS AJ, ansonsten wenn EPS AJ vorhanden: analog, nur mit (EPS AJ-EPS VJ)/EPS VJ, sonst 0\n",
    "\n",
    "df_eps_current_year = pd.DataFrame()\n",
    "df_eps_next_year = pd.DataFrame()\n",
    "df_eps_last = pd.DataFrame()\n",
    "df_peg = pd.DataFrame()\n",
    "\n",
    "# Gewinnprognosen für laufendes Geschäftsjahr und für nächstes Jahr abfragen und in 2 Dataframes abspeichern\n",
    "df_eps_current_year = df_earnings_future[df_earnings_future[\"period\"] == \"0y\"][[\"symbol\", \"period\", \"epsTrend_current\"]]\n",
    "df_eps_next_year = df_earnings_future[df_earnings_future[\"period\"] == \"+1y\"][[\"symbol\", \"period\", \"epsTrend_current\"]]\n",
    "df_eps_current_year = df_eps_current_year.rename(columns={\"epsTrend_current\": \"eps\"})\n",
    "df_eps_next_year = df_eps_next_year.rename(columns={\"epsTrend_current\": \"eps\"})\n",
    "\n",
    "# Abfrage der EPS des vergangenen Geschäftsjahres\n",
    "df_eps_last = df_fundamentals[df_fundamentals[\"periodType\"] == \"12M\"][[\"symbol\", \"asOfDate\", \"DilutedEPS\"]]\n",
    "df_eps_last = df_eps_last.sort_values(\"asOfDate\", ascending=False)\n",
    "df_eps_last = df_eps_last.groupby(\"symbol\").first()\n",
    "df_eps_last = df_eps_last.rename(columns={\"DilutedEPS\": \"eps_last\"})\n",
    "\n",
    "df_eps_current_year = df_eps_current_year.set_index(\"symbol\")\n",
    "df_eps_next_year = df_eps_next_year.set_index(\"symbol\")\n",
    "\n",
    "#Dataframes zusammenführen\n",
    "df_peg = pd.merge(df_eps_current_year, df_eps_next_year, how=\"left\", left_index=True, right_index=True, suffixes=(\"_current\",\"_next\"))\n",
    "df_peg = pd.merge(df_peg, df_eps_last, how=\"left\", left_index=True, right_index=True, suffixes=(\"\",\"_last\"))\n",
    "\n",
    "def calculate_peg(row):\n",
    "    now = row[\"period_current\"]\n",
    "    nxt = row[\"period_next\"]\n",
    "    last = row[\"asOfDate\"]\n",
    "    eps_now = row[\"eps_current\"]\n",
    "    eps_next = row[\"eps_next\"]\n",
    "    eps_last = row[\"eps_last\"]\n",
    "    if any(x is None or pd.isnull(x) or pd.isna(x) or x == \"\" for x in (now, nxt, last, eps_now, eps_next, eps_last)):\n",
    "        return \"keine Daten\"\n",
    "    elif eps_now > 0:\n",
    "        if ((eps_next - eps_now)) / eps_now > 0.05:\n",
    "            return 1\n",
    "        elif (((eps_next - eps_now)) / eps_now <= 0.05) and (((eps_next - eps_now)) / eps_now >= -0.05):\n",
    "            return 0\n",
    "        elif ((eps_next - eps_now)) / eps_now < -0.05:\n",
    "            return -1\n",
    "    else:\n",
    "        if ((eps_now - eps_last) / eps_last) > 0.05:\n",
    "            return 1\n",
    "        elif (((eps_now - eps_last) / eps_last) <= 0.05) and (((eps_now - eps_last) / eps_last) >= -0.05):\n",
    "            return 0\n",
    "        elif ((eps_now - eps_last) / eps_last) < -0.05:\n",
    "            return -1\n",
    "    \n",
    "df_results[\"peg\"] = df_peg.apply(calculate_peg, axis=1)\n",
    "df_peg[\"Score PEG\"] = df_peg.apply(calculate_peg, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ergebnisspalten\n",
    "result_columns = ['RoE', \n",
    "                   'EBIT margin', \n",
    "                   'equity ratio', \n",
    "                   'pe_ratio_5yr',\n",
    "                   'pe_ratio_current',\n",
    "                   'analysts_opinion', \n",
    "                   'earnings reaction',\n",
    "                   'earnings revisions', \n",
    "                   '6 months performance', \n",
    "                   '1 year performance',\n",
    "                   'momentum',\n",
    "                   '3 months reversal',\n",
    "                   'peg'\n",
    "                   ]\n",
    "\n",
    "# In den Ergebnisspalten NULL-Werte auffüllen\n",
    "df_results[result_columns] = df_results[result_columns].fillna(0)\n",
    "\n",
    "# Gesamptpunktzahl ermitteln\n",
    "df_results[\"total score\"] = df_results.apply(lambda row: np.sum([x for col, x in row.items() if col in result_columns and (isinstance(x, int) or isinstance(x, float))]), axis=1)\n",
    "\n",
    "# Anzahl leerer Spalten ermitteln\n",
    "df_results[\"criteria available\"] = df_results.apply(lambda row: np.sum([1 for col, x in row.items() if col in result_columns and (isinstance(x, int) or isinstance(x, float))]), axis=1)\n",
    "df_results[\"criteria empty\"] = df_results.apply(lambda row: sum(1 for col, x in row.items() if col in result_columns and (pd.isna(x) or x == \"\" or x == \"keine Daten\" or x == \"Division durch Null (EPS alt = Null)\")), axis=1)\n",
    "\n",
    "# Berechnungen zum \"fairen\" Preis basierend auf dem KGV und der erreichten Punktzahl:\n",
    "# Funktion zur Ermittlung des KGV\n",
    "def calculate_pe(row):\n",
    "    price = row[\"previous close\"]\n",
    "    earnings_current = row[\"EPS_current\"]\n",
    "    earnings_past = row[\"EPS_last\"]\n",
    "    if (earnings_current is None) | (earnings_current == 0) | (earnings_current == \"\"):\n",
    "        if (earnings_past is None) | (earnings_past == 0) | (earnings_past == \"\"):\n",
    "            return \"keine Daten\"\n",
    "        else:\n",
    "            return (price/earnings_past)\n",
    "    else: \n",
    "        return (price/earnings_current)\n",
    "    \n",
    "df_results[\"PE ratio\"] = df_pe_current_results.apply(calculate_pe, axis=1)\n",
    "\n",
    "# Maximaler Preis unter Berücksichtigung der Kriterien:\n",
    "# PE maximal 15, außer:\n",
    "#   Punkte mind. 5 (leere Felder zählen als 0)\n",
    "#   Für jeden Punkt über 5 Punkten wird zum maximalen PE von 16 1 dazu addiert\n",
    "# Basierend darauf wird der maximale Limitpreis ermittelt anhand der EPS des laufenden Jahres (falls vorhanden), ansonsten anhand des Vorjahres\n",
    "df_pe_fair_combined = pd.DataFrame()\n",
    "df_total_score = pd.DataFrame()\n",
    "df_pe_fair = pd.DataFrame()\n",
    "df_pe_fair = pd.DataFrame(df_pe_current_results)\n",
    "df_pe_future = pd.DataFrame()\n",
    "df_pe_future = pd.DataFrame(df_earnings_future[df_earnings_future[\"period\"] == \"0y\"][[\"epsTrend_current\", \"symbol\"]])\n",
    "df_pe_future = df_pe_future.set_index(\"symbol\")\n",
    "df_total_score = pd.DataFrame(df_results[\"total score\"])\n",
    "df_pe_fair_combined = pd.merge(df_pe_fair, df_pe_future, how=\"left\", left_index=True, right_index=True)\n",
    "df_pe_fair_combined = pd.merge(df_pe_fair, df_total_score, how=\"left\", left_index=True, right_index=True)\n",
    "\n",
    "def calculate_max_pe(row):\n",
    "    multiple_base = row[\"total score\"]\n",
    "    if (multiple_base is None) or (multiple_base == 0) or (multiple_base == \"\"):\n",
    "        return \"keine Daten\"\n",
    "    else:\n",
    "        if multiple_base <= 5:\n",
    "            return 16\n",
    "        elif (multiple_base > 5) and (multiple_base <= 13):\n",
    "            return (16 + multiple_base - 5)\n",
    "        else:\n",
    "            return \"Fehler\"\n",
    "\n",
    "def calculate_price_max_current(row):\n",
    "    eps_now = row[\"EPS_current\"]\n",
    "    eps_old = row[\"EPS_last\"]\n",
    "    multiple = row[\"total score\"]\n",
    "    if (eps_now is None) or (eps_now == 0) or (eps_now == \"\") or (multiple == \"Fehler\"):\n",
    "        if (eps_old is None) or (eps_old == 0) or (eps_old == \"\") or (multiple == \"Fehler\"):\n",
    "            return \"keine Daten\"\n",
    "        else:\n",
    "            return eps_old\n",
    "    else:\n",
    "        return eps_now\n",
    "\n",
    "def calculate_price_max_future(row):\n",
    "    eps = row[\"EPS_current\"]\n",
    "    multiple = row[\"total score\"]\n",
    "    if (eps is None) or (eps == 0) or (eps == \"\") or (multiple == \"Fehler\"):\n",
    "        return \"keine Daten\"\n",
    "    else:\n",
    "        return eps\n",
    "\n",
    "df_results[\"PE ratio (max) for order\"] = df_pe_fair_combined.apply(calculate_max_pe, axis=1)\n",
    "df_results[\"price_component_1\"] = df_pe_fair_combined.apply(calculate_max_pe, axis=1)\n",
    "df_results[\"price_component_2\"] = df_pe_fair_combined.apply(calculate_price_max_current, axis=1)\n",
    "df_results[\"future_price_component_2\"] = df_pe_fair_combined.apply(calculate_price_max_future, axis=1)\n",
    "\n",
    "# Konvertieren in float-Datentyp\n",
    "df_results[\"price_component_1\"] = df_results[\"price_component_1\"].replace([\"keine Daten\", \"Fehler\"], float(\"NaN\"))\n",
    "df_results[\"price_component_2\"] = df_results[\"price_component_2\"].replace([\"keine Daten\", \"Fehler\"], float(\"NaN\"))\n",
    "df_results[\"future_price_component_2\"] = df_results[\"price_component_2\"].replace(\"keine Daten\", float(\"NaN\"))\n",
    "df_results[\"price_component_1\"] = df_results[\"price_component_1\"].astype(float)\n",
    "df_results[\"price_component_2\"] = df_results[\"price_component_2\"].astype(float)\n",
    "df_results[\"future_price_component_2\"] = df_results[\"price_component_2\"].astype(float)\n",
    "\n",
    "# Ergebnisse erzeugen\n",
    "df_results[\"price (max) for order\"] = df_results.apply(lambda row: row[\"price_component_1\"] * row[\"price_component_2\"], axis=1)\n",
    "df_results[\"future price (max) for order\"] = df_results.apply(lambda row: row[\"price_component_1\"] * row[\"future_price_component_2\"], axis=1)\n",
    "df_results = df_results.drop([\"price_component_1\", \"price_component_2\", \"future_price_component_2\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_sheets = [df_analysts, \n",
    "               df_ebit_latest, \n",
    "               df_pe_5_results, \n",
    "               df_pe_current_results, \n",
    "               df_history_announcements, \n",
    "               df_revisions, \n",
    "               df_6_months_comparison, \n",
    "               df_1_year_comparison, \n",
    "               df_momentum, \n",
    "               df_1to3_months_comparison, \n",
    "               df_peg\n",
    "               ]\n",
    "\n",
    "list_master_data = [df_prices, \n",
    "                    df_fundamentals, \n",
    "                    df_fundamentals_current, \n",
    "                    df_earnings, \n",
    "                    df_earnings_future\n",
    "                    ]\n",
    "\n",
    "dict_sheets = {\"Analystenmeinung\": df_analysts, \n",
    "               \"EBIT\": df_ebit_latest, \n",
    "               \"5-Jahres-KGV\": df_pe_5_results, \n",
    "               \"KGV aktuell\": df_pe_current_results, \n",
    "               \"Reaktion auf Quartalszahlen\": df_history_announcements, \n",
    "               \"Gewinnrevisionen\": df_revisions, \n",
    "               \"6-Monats-Performance\": df_6_months_comparison, \n",
    "               \"1-Jahres-Performance\": df_1_year_comparison, \n",
    "               \"Kursmomentum\": df_momentum, \n",
    "               \"3-Monats_Reversal\": df_1to3_months_comparison, \n",
    "               \"Gewinnwachstum\": df_peg\n",
    "               }\n",
    "dict_master_data = {\"Kurse\": df_prices, \n",
    "                    \"Fundamental-KPIs\": df_fundamentals, \n",
    "                    \"Fundamental-KPIs_aktuell\": df_fundamentals_current, \n",
    "                    \"Quartalszahlen\": df_earnings, \n",
    "                    \"Quartalszahlen Prognose\": df_earnings_future\n",
    "                    } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HannesDuerr\\AppData\\Local\\Temp\\ipykernel_1828\\1877222745.py:7: DeprecationWarning: Call to deprecated function copy (Use copy(obj) or cell.obj = cell.obj + other).\n",
      "  cell.font = cell.font.copy(bold=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die Ergebnisse wurden in der Datei Ergebnisse Bewertung_per 2023-08-18_14-56-27.xlsx im Verzeichnis C:/Users/HannesDuerr/OneDrive - Deutsche Bahn/Data Science gespeichert.\n",
      "Die Laufzeit des Skripts betrug 589.40 Sekunden.\n"
     ]
    }
   ],
   "source": [
    "# Erstellen eines Styler-Objekts für die Formatierung\n",
    "def format_sheet(sheet):\n",
    "    # Hintergrundfarbe für Überschriften\n",
    "    header_fill = PatternFill(start_color=\"DDDDDD\", end_color=\"DDDDDD\", fill_type=\"solid\")\n",
    "    # Spaltenüberschriften fett formatieren\n",
    "    for cell in sheet[1]:\n",
    "        cell.font = cell.font.copy(bold=True)\n",
    "    # Hintergrundfarbe für Überschriften anwenden\n",
    "    for cell in sheet[1]:\n",
    "        cell.fill = header_fill\n",
    "    # Spaltenbreite anpassen\n",
    "    for column in sheet.columns:\n",
    "        max_length = 0\n",
    "        column_letter = get_column_letter(column[0].column)\n",
    "        for cell in sheet[column_letter]:\n",
    "            try:\n",
    "                if len(str(cell.value)) > max_length:\n",
    "                    max_length = len(cell.value)\n",
    "            except:\n",
    "                pass\n",
    "        adjusted_width = (max_length + 2) * 1.2  # 1.2 entspricht ungefähr 1 Pixel pro Zeichen\n",
    "        sheet.column_dimensions[column_letter].width = adjusted_width\n",
    "    return sheet\n",
    "\n",
    "# Ergebnisse in Excel-Datei schreiben\n",
    "output_path = os.path.dirname(input_data)\n",
    "output_file = \"Ergebnisse Bewertung_per \" + dt.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\") + \".xlsx\"\n",
    "output_data = os.path.join(output_path, output_file)\n",
    "\n",
    "# Sortieren des Dataframes \"df_results\" nach dem Index\n",
    "\n",
    "merged_results = pd.merge(df_input_data, df_results, left_on=\"Symbol (Yahoo)\", right_index=True, how=\"left\")\n",
    "\n",
    "# Ergebnisdatei erstellen\n",
    "with pd.ExcelWriter(output_data, engine='openpyxl') as my_writer:\n",
    "    # Inputdaten aus der Quellexceldatei in Ergebnisdatei kopieren und die Formatierung beibehalten\n",
    "    merged_results.to_excel(my_writer, sheet_name=\"Ergebnisse\", index=False)\n",
    "    workbook = my_writer.book\n",
    "    worksheet = workbook[\"Ergebnisse\"]\n",
    "    format_sheet(worksheet)\n",
    "    worksheet.auto_filter.ref = worksheet.dimensions\n",
    "    # Weitere Tabellenblätter formatieren\n",
    "    for key, value in dict_sheets.items():\n",
    "        value.to_excel(my_writer, sheet_name=key, index=False)\n",
    "        worksheet = workbook[key]\n",
    "        format_sheet(worksheet)\n",
    "        worksheet.auto_filter.ref = worksheet.dimensions\n",
    "    workbook.save(output_data)\n",
    "\n",
    "# Endzeitpunkt erfassen\n",
    "end_time = time.time()\n",
    "\n",
    "# Gesamtdauer berechnen\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "print(f\"Die Ergebnisse wurden in der Datei {output_file} im Verzeichnis {output_path} gespeichert.\")\n",
    "print(f\"Die Laufzeit des Skripts betrug {execution_time:.2f} Sekunden.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
